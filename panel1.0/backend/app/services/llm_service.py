"""Claude LLM íˆ´ì½œ ì—°ë™ ì„œë¹„ìŠ¤"""
from typing import Any, Dict, List
from datetime import date, datetime
from decimal import Decimal
import os
from anthropic import Anthropic
from app.services.sql_service import execute_sql_safe


SQL_TOOL = {
    "name": "execute_sql",
    "description": "ì•ˆì „í•œ ì½ê¸° ì „ìš© SQLì„ ì‹¤í–‰í•©ë‹ˆë‹¤. SELECT/WITHë§Œ í—ˆìš©ë©ë‹ˆë‹¤.",
    "input_schema": {
        "type": "object",
        "properties": {
            "query": {"type": "string", "description": "SELECT ë˜ëŠ” WITHë¡œ ì‹œì‘í•˜ëŠ” ì¿¼ë¦¬"},
            "params": {"type": "object", "description": "ë°”ì¸ë”© íŒŒë¼ë¯¸í„° (ëª…ëª…ëœ ë°”ì¸ë”©)"},
            "limit": {"type": "integer", "minimum": 1, "maximum": 1000, "default": 200},
            "statement_timeout_ms": {"type": "integer", "minimum": 100, "maximum": 20000, "default": 5000},
        },
        "required": ["query"],
    },
}


class LlmService:
    def __init__(self) -> None:
        api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not api_key:
            raise RuntimeError("ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        self.client = Anthropic(api_key=api_key)
        self._default_model = os.environ.get("ANTHROPIC_MODEL", "claude-3-5-haiku-latest")

    def get_default_model(self) -> str:
        return self._default_model
    
    def _get_db_schema_info(self) -> str:
        """ì‹¤ì œ DB ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜ (LLMì—ê²Œ ì œê³µ)"""
        try:
            # ëª¨ë“  ìŠ¤í‚¤ë§ˆì˜ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
            tables = execute_sql_safe(
                query=(
                    "SELECT t.table_schema, t.table_name "
                    "FROM information_schema.tables t "
                    "WHERE t.table_schema NOT IN ('pg_catalog', 'information_schema', 'pg_toast') "
                    "  AND t.table_type='BASE TABLE' "
                    "ORDER BY t.table_schema, t.table_name"
                ),
                limit=50,
            )
            
            schema_info_parts = []
            
            for tbl in tables:
                schema_name = tbl['table_schema']
                tbl_name = tbl['table_name']
                
                # ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
                cols = execute_sql_safe(
                    query=(
                        "SELECT column_name, data_type, is_nullable "
                        "FROM information_schema.columns "
                        "WHERE table_schema=%(schema)s AND table_name=%(tbl)s "
                        "ORDER BY ordinal_position"
                    ),
                    params={"schema": schema_name, "tbl": tbl_name},
                    limit=200,
                )
                
                # ì»¬ëŸ¼ ëª©ë¡ ë¬¸ìì—´ ìƒì„±
                col_list = []
                for col in cols:
                    col_name = col['column_name']
                    col_type = col['data_type']
                    nullable = "NULL" if col['is_nullable'] == 'YES' else "NOT NULL"
                    col_list.append(f"{col_name} ({col_type}, {nullable})")
                
                # í…Œì´ë¸” ì •ë³´ ë¬¸ìì—´ ìƒì„±
                full_table_name = f'"{schema_name}"."{tbl_name}"'
                schema_info_parts.append(
                    f"- {full_table_name}:\n  ì»¬ëŸ¼: {', '.join(col_list[:10])}"  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                )
            
            return "\n".join(schema_info_parts)
        except Exception as e:
            return f"ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"

    def ask_with_tools(self, user_prompt: str, model: str | None = None) -> Dict[str, Any]:
        if not model:
            model = self.get_default_model()
        """
        - ë‹¨ì¼ í„´ì—ì„œ ìµœëŒ€ 1íšŒì˜ íˆ´ì½œì„ ì²˜ë¦¬ (ë°ëª¨ìš©)
        - ëª¨ë¸ì´ execute_sql íˆ´ì„ í˜¸ì¶œí•˜ë©´ ì„œë²„ì—ì„œ ì‹¤í–‰ í›„ tool_resultë¥¼ ì²¨ë¶€í•˜ì—¬ ì¬í˜¸ì¶œ
        """
        initial = self.client.messages.create(
            model=model,
            max_tokens=1024,
            temperature=0,
            tools=[SQL_TOOL],
            tool_choice={"type": "auto"},
            messages=[{"role": "user", "content": user_prompt}],
        )

        content = initial.content
        tool_use = next((c for c in content if getattr(c, "type", None) == "tool_use"), None)

        if not tool_use:
            # íˆ´ì½œ ì—†ì´ ë°”ë¡œ ë‹µë³€
            text = "\n".join(getattr(c, "text", "") for c in content if getattr(c, "type", None) == "text")
            return {"answer": text, "tool_called": False}

        if tool_use.name != "execute_sql":
            return {"answer": "ì§€ì›ë˜ì§€ ì•ŠëŠ” íˆ´ í˜¸ì¶œì…ë‹ˆë‹¤.", "tool_called": True}

        args = tool_use.input or {}
        try:
            raw_rows = execute_sql_safe(
                query=args.get("query", ""),
                params=args.get("params", {}),
                limit=int(args.get("limit", 200)),
                statement_timeout_ms=int(args.get("statement_timeout_ms", 5000)),
            )
            # JSON ì§ë ¬í™” ì•ˆì „ ì²˜ë¦¬
            def _conv(v: Any) -> Any:
                if isinstance(v, (date, datetime)):
                    return v.isoformat()
                if isinstance(v, Decimal):
                    return float(v)
                return v
            rows: List[Dict[str, Any]] = [
                {k: _conv(v) for k, v in r.items()} for r in raw_rows
            ]
            tool_result_payload = {"rows": rows, "count": len(rows)}
        except Exception as e:
            tool_result_payload = {"error": str(e)}

        followup = self.client.messages.create(
            model=model,
            max_tokens=1024,
            temperature=0,
            tools=[SQL_TOOL],
            messages=[
                {"role": "user", "content": user_prompt},
                {
                    "role": "assistant",
                    "content": [
                        {"type": "tool_use", "id": tool_use.id, "name": "execute_sql", "input": args},
                    ],
                },
                {"role": "user", "content": [{"type": "tool_result", "tool_use_id": tool_use.id, "content": tool_result_payload}]},
            ],
        )

        final_text = "\n".join(getattr(c, "text", "") for c in followup.content if getattr(c, "type", None) == "text")
        return {"answer": final_text, "tool_called": True, "tool_result_preview": str(tool_result_payload)[:500]}

    def ask_for_sql_rows(self, user_prompt: str, model: str | None = None, conversation_history: List[Dict[str, Any]] | None = None, panel_search_result: Dict[str, Any] | None = None) -> Dict[str, Any]:
        if not model:
            model = self.get_default_model()
        """
        ì‹¤ì œ DB ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SQL-íˆ´ì½œì„ ìœ ë„í•˜ì—¬ ê²°ê³¼ rows/countë¥¼ ë°˜í™˜.
        - SELECT/WITHë§Œ í—ˆìš©ë¨ì„ ëª…ì‹œ
        - ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡°ë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ LLMì—ê²Œ ì œê³µ
        - ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì§€ì›í•˜ì—¬ ì—°ì†ì ì¸ ëŒ€í™” ê°€ëŠ¥
        - íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°›ì•„ì„œ ì¼ê´€ëœ ë‹µë³€ ìƒì„±
        """
        # ì‹¤ì œ DB ìŠ¤í‚¤ë§ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        db_schema = self._get_db_schema_info()
        
        # íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        panel_result_context = ""
        if panel_search_result:
            estimated_count = panel_search_result.get('estimatedCount', 0)
            distribution_stats = panel_search_result.get('distributionStats', {})
            extracted_chips = panel_search_result.get('extractedChips', [])
            previous_panel_ids = panel_search_result.get('previousPanelIds', [])
            
            panel_result_context = "\n\n=== íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ (ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”) ===\n"
            
            # ì´ì „ ì¶”ì¶œ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ì§ˆì˜ì¸ì§€ í‘œì‹œ
            if previous_panel_ids and len(previous_panel_ids) > 0:
                panel_result_context += f"âš ï¸ ì¤‘ìš”: ì´ ì§ˆì˜ëŠ” ì´ì „ì— ì¶”ì¶œëœ {len(previous_panel_ids):,}ëª…ì˜ íŒ¨ë„ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n"
                panel_result_context += "ì´ íŒ¨ë„ë“¤ ì¤‘ì—ì„œ ì¶”ê°€ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” íŒ¨ë„ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.\n\n"
            
            panel_result_context += f"ì´ íŒ¨ë„ ìˆ˜: {estimated_count:,}ëª…\n"
            
            if extracted_chips:
                panel_result_context += f"ì¶”ì¶œëœ ì¡°ê±´: {', '.join(extracted_chips)}\n"
            
            if distribution_stats:
                gender_stats = distribution_stats.get('gender', [])
                age_stats = distribution_stats.get('age', [])
                region_stats = distribution_stats.get('region', [])
                
                if gender_stats:
                    panel_result_context += "\nì„±ë³„ ë¶„í¬:\n"
                    for stat in gender_stats:
                        panel_result_context += f"  - {stat.get('label', 'N/A')}: {stat.get('value', 0):,}ëª…\n"
                
                if age_stats:
                    panel_result_context += "\nì—°ë ¹ëŒ€ ë¶„í¬:\n"
                    for stat in age_stats:
                        panel_result_context += f"  - {stat.get('label', 'N/A')}: {stat.get('value', 0):,}ëª…\n"
                
                if region_stats:
                    panel_result_context += "\nì§€ì—­ ë¶„í¬ (ìƒìœ„ 10ê°œ):\n"
                    for stat in region_stats[:10]:
                        panel_result_context += f"  - {stat.get('label', 'N/A')}: {stat.get('value', 0):,}ëª…\n"
            
            panel_result_context += "\nì¤‘ìš”: ìœ„ íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ì˜ ì´ íŒ¨ë„ ìˆ˜ì™€ ë¶„í¬ í†µê³„ë¥¼ ì •í™•íˆ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”. SQLì„ ì‹¤í–‰í•˜ì§€ ë§ê³  ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.\n"
        
        system_hint = (
            "ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ë³´ì¡°ì…ë‹ˆë‹¤. ì‚¬ìš©ì ìš”ì²­ì„ ì½ê³ , ë°˜ë“œì‹œ SELECT ë˜ëŠ” WITHë¡œ ì‹œì‘í•˜ëŠ” "
            "í•˜ë‚˜ì˜ ì½ê¸° ì „ìš© SQLë§Œ ì‚¬ìš©í•˜ì„¸ìš”. SQL ì¿¼ë¦¬ì—ëŠ” ì„¸ë¯¸ì½œë¡ (;)ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n\n"
            "=== ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ ===\n"
            f"{db_schema}\n\n"
            "=== ì¤‘ìš” ì‚¬í•­ ===\n"
            "1. í…Œì´ë¸”ëª…ì€ ìŠ¤í‚¤ë§ˆë¥¼ í¬í•¨í•˜ì—¬ \"ìŠ¤í‚¤ë§ˆëª…\".\"í…Œì´ë¸”ëª…\" í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
            "2. SQL ì¿¼ë¦¬ì—ëŠ” ì ˆëŒ€ ì„¸ë¯¸ì½œë¡ (;)ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. ë‹¨ì¼ SELECT ë¬¸ë§Œ ì‘ì„±í•˜ì„¸ìš”.\n"
            "3. íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ê°€ ì œê³µëœ ê²½ìš°, SQLì„ ì‹¤í–‰í•˜ì§€ ë§ê³  ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.\n"
            "4. core.join_clean í…Œì´ë¸”: íŒ¨ë„ ê¸°ë³¸ ì •ë³´\n"
            "   - gender: 'ë‚¨'/'ì—¬'\n"
            "   - region: ì§€ì—­ëª… (ì˜ˆ: 'ì„œìš¸', 'ë¶€ì‚°')\n"
            "   - age_text: '1987ë…„ 06ì›” 29ì¼ (ë§Œ 38 ì„¸)' í˜•ì‹\n"
            "   - respondent_id: íŒ¨ë„ ID\n"
            "   - q_concat: ì§ˆë¬¸ ë‹µë³€ ë²ˆí˜¸ (ìˆ«ì)\n"
            "5. core.docs_json í…Œì´ë¸”: ìƒì„¸ ë‹µë³€ ë°ì´í„° (JSONB)\n"
            "   - doc: jsonb íƒ€ì…, êµ¬ì¡°: {answers: {...}, gender, region, age_text, ...}\n"
            "6. core.poll_question í…Œì´ë¸”: ì§ˆë¬¸ í…ìŠ¤íŠ¸\n"
            "   - question_text: ì§ˆë¬¸ ë‚´ìš©\n"
            "   - poll_code: ì„¤ë¬¸ ì½”ë“œ\n"
            "   - q_no: ì§ˆë¬¸ ë²ˆí˜¸\n"
            "7. core.poll_option í…Œì´ë¸”: ë‹µë³€ ì˜µì…˜ í…ìŠ¤íŠ¸\n"
            "   - opt_text: ë‹µë³€ ì˜µì…˜ í…ìŠ¤íŠ¸ (ì˜ˆ: 'ë„·í”Œë¦­ìŠ¤', 'ë””ì¦ˆë‹ˆ í”ŒëŸ¬ìŠ¤', 'ìœ íŠœë¸Œ', 'ìš´ë™', 'ë‹¬ë¦¬ê¸°' ë“±)\n"
            "   - poll_code: ì„¤ë¬¸ ì½”ë“œ\n"
            "   - q_no: ì§ˆë¬¸ ë²ˆí˜¸\n"
            "   - opt_no: ì˜µì…˜ ë²ˆí˜¸\n"
            "8. core.poll_option_count í…Œì´ë¸”: ì˜µì…˜ë³„ ì‘ë‹µ ìˆ˜\n"
            "9. ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ë°©ë²• (ì˜ˆ: 'ë‹¬ë¦¬ëŠ” ê±¸ ì¢‹ì•„í•˜ëŠ”'):\n"
            "   ë‹¨ê³„ 1: poll_optionì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì˜µì…˜ ì°¾ê¸°\n"
            "     SELECT opt_no, q_no, poll_code FROM \"core\".\"poll_option\"\n"
            "     WHERE opt_text LIKE '%ë‹¬ë¦¬%' OR opt_text LIKE '%ëŸ¬ë‹%' OR opt_text LIKE '%ì¡°ê¹…%' OR opt_text LIKE '%ìš´ë™%'\n"
            "   ë‹¨ê³„ 2: join_cleanì˜ q_concatì—ì„œ í•´ë‹¹ ì˜µì…˜ ë²ˆí˜¸ê°€ í¬í•¨ëœ ì‚¬ëŒ ì°¾ê¸°\n"
            "     SELECT * FROM \"core\".\"join_clean\"\n"
            "     WHERE region LIKE '%ì„œìš¸%'\n"
            "       AND gender = 'ë‚¨'\n"
            "       AND CAST(SUBSTRING(age_text FROM 'ë§Œ (\\d+) ì„¸') AS INTEGER) BETWEEN 30 AND 39\n"
            "       AND q_concat LIKE '%2%'  -- ì˜ˆ: opt_no=2ì¸ ê²½ìš°\n"
            "   ë˜ëŠ” JOIN ì‚¬ìš©:\n"
            "     SELECT DISTINCT jc.respondent_id\n"
            "     FROM \"core\".\"join_clean\" jc\n"
            "     JOIN \"core\".\"poll_option\" po ON jc.q_concat LIKE '%' || po.opt_no::text || '%'\n"
            "     WHERE jc.region LIKE '%ì„œìš¸%'\n"
            "       AND jc.gender = 'ë‚¨'\n"
            "       AND CAST(SUBSTRING(jc.age_text FROM 'ë§Œ (\\d+) ì„¸') AS INTEGER) BETWEEN 30 AND 39\n"
            "       AND (po.opt_text LIKE '%ë‹¬ë¦¬%' OR po.opt_text LIKE '%ëŸ¬ë‹%' OR po.opt_text LIKE '%ì¡°ê¹…%' OR po.opt_text LIKE '%ìš´ë™%')\n"
            "   LIMIT 100\n"
            "10. ì„±ë³„ì€ 'ë‚¨'/'ì—¬' ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
            "11. ì—°ë ¹ëŒ€ í•„í„°ë§:\n"
            "   - age_text ì»¬ëŸ¼: CAST(SUBSTRING(age_text FROM 'ë§Œ (\\d+) ì„¸') AS INTEGER) BETWEEN 20 AND 29\n"
            "   - birthdate ì»¬ëŸ¼: (EXTRACT(YEAR FROM CURRENT_DATE)-EXTRACT(YEAR FROM birthdate)) BETWEEN 20 AND 29\n"
            "12. ì§€ì—­ í•„í„°ë§: region LIKE '%ì„œìš¸%' í˜•ì‹ ì‚¬ìš©\n"
            "13. JOIN ì˜ˆì‹œ: core.join_cleanê³¼ core.docs_jsonì„ respondent_idë¡œ ì¡°ì¸í•˜ì—¬ í•„í„°ë§\n"
            "14. íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ê°€ ì œê³µë˜ë©´ SQLì„ ì‹¤í–‰í•˜ì§€ ë§ê³ , ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.\n"
            "15. ì§ˆë¬¸ì— ì§ì ‘ ë‹µí•˜ì§€ ë§ê³ , í•„ìš” ì‹œ íˆ´ì½œ í›„ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì„¸ìš”.\n"
            "16. ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì‚¬ìš©ìì˜ ì—°ì†ì ì¸ ì§ˆë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”."
            f"{panel_result_context}"
        )

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
        messages = []
        if conversation_history:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ Claude API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            for msg in conversation_history:
                if isinstance(msg, dict) and 'role' in msg and 'content' in msg:
                    messages.append({
                        "role": msg['role'],
                        "content": str(msg['content'])
                    })
        
        # í˜„ì¬ ì‚¬ìš©ì ì§ˆì˜ ì¶”ê°€
        messages.append({"role": "user", "content": user_prompt})

        # íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ SQL ì‹¤í–‰ ì—†ì´ ë°”ë¡œ ë‹µë³€ ìƒì„±
        if panel_search_result:
            # íŒ¨ë„ ê²€ìƒ‰ ê²°ê³¼ê°€ ì œê³µëœ ê²½ìš°, SQLì„ ì‹¤í–‰í•˜ì§€ ì•Šê³  ì§ì ‘ ë‹µë³€ ìƒì„±
            direct_response = self.client.messages.create(
                model=model,
                max_tokens=1024,
                temperature=0,
                system=system_hint,
                messages=messages,
            )
            text = "\n".join(getattr(c, "text", "") for c in direct_response.content if getattr(c, "type", None) == "text")
            return {"answer": text, "tool_called": False}

        initial = self.client.messages.create(
            model=model,
            max_tokens=1024,
            temperature=0,
            tools=[SQL_TOOL],
            tool_choice={"type": "auto"},
            system=system_hint,
            messages=messages,
        )

        content = initial.content
        tool_use = next((c for c in content if getattr(c, "type", None) == "tool_use"), None)
        if not tool_use:
            text = "\n".join(getattr(c, "text", "") for c in content if getattr(c, "type", None) == "text")
            return {"answer": text, "tool_called": False}

        args = tool_use.input or {}
        try:
            rows = execute_sql_safe(
                query=args.get("query", ""),
                params=args.get("params", {}),
                limit=int(args.get("limit", 200)),
                statement_timeout_ms=int(args.get("statement_timeout_ms", 5000)),
            )
            # JSON ì§ë ¬í™” ì•ˆì „ ì²˜ë¦¬
            def _conv(v: Any) -> Any:
                if isinstance(v, (date, datetime)):
                    return v.isoformat()
                if isinstance(v, Decimal):
                    return float(v)
                return v
            rows_clean: List[Dict[str, Any]] = [
                {k: _conv(v) for k, v in r.items()} for r in rows
            ]
            tool_result_payload = {"rows": rows_clean, "count": len(rows_clean)}
        except Exception as e:
            tool_result_payload = {"error": str(e)}

        # tool_resultì˜ contentëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•¨ (JSON ë¬¸ìì—´ë¡œ ë³€í™˜)
        import json as json_lib
        tool_result_content = json_lib.dumps(tool_result_payload, ensure_ascii=False, default=str)

        # followup ë©”ì‹œì§€ì—ë„ ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨
        followup_messages = []
        if conversation_history:
            for msg in conversation_history:
                if isinstance(msg, dict) and 'role' in msg and 'content' in msg:
                    followup_messages.append({
                        "role": msg['role'],
                        "content": str(msg['content'])
                    })
        
        followup_messages.extend([
            {"role": "user", "content": user_prompt},
            {"role": "assistant", "content": [{"type": "tool_use", "id": tool_use.id, "name": "execute_sql", "input": args}]},
            {"role": "user", "content": [{"type": "tool_result", "tool_use_id": tool_use.id, "content": tool_result_content}]},
        ])

        followup = self.client.messages.create(
            model=model,
            max_tokens=1024,
            temperature=0,
            tools=[SQL_TOOL],
            system=system_hint,
            messages=followup_messages,
        )

        final_text = "\n".join(getattr(c, "text", "") for c in followup.content if getattr(c, "type", None) == "text")
        return {"answer": final_text, "tool_called": True, **tool_result_payload}

    def list_models(self) -> Dict[str, Any]:
        models = self.client.models.list()
        names = [m.id for m in getattr(models, 'data', [])]
        return {"models": names}
    
    def generate_semantic_search_sql(self, user_question: str, model: str | None = None) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ì„œ semantic searchë¥¼ ìœ„í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Returns:
            {
                "search_text": "ë²¡í„°í™”í•  ê²€ìƒ‰ ë¬¸êµ¬",
                "sql": "SELECT ... WHERE embedding <=> '<VECTOR>'::vector ..."
            }
        """
        if not model:
            model = self.get_default_model()
        
        system_prompt = """You are the AI reasoning and SQL generation engine for a hybrid search system
that supports two modes:

1) Panel Search Mode (Structured SQL Filtering)
2) Semantic Search Mode (Embedding-based Vector Search)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ DATABASE FACTS  (ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•¨)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- All document vectors (1024-dimension, KURE v1) are stored in:
      core.doc_embedding (columns: doc_id, embedding, model_name, created_at)

- The actual text used for embedding is stored in:
      core.doc_embedding_view.embedding_text

- To perform semantic search, you MUST always JOIN:
      core.doc_embedding_view AS v
      core.doc_embedding      AS e
  using v.doc_id = e.doc_id

- Do NOT apply similarity thresholds. Use ORDER BY distance LIMIT 10.

- Backend replaces <VECTOR> with the 1024-dim vector generated by KURE v1.
  NEVER generate embeddings yourself.

Table schema:
    core.doc_embedding(
        doc_id BIGINT,
        embedding VECTOR(1024),
        model_name TEXT,
        created_at TIMESTAMP
    )
    
    core.doc_embedding_view(
        doc_id BIGINT,
        embedding_text TEXT,
        gender TEXT,
        age_text TEXT,
        region TEXT,
        poll_code TEXT,
        respondent_id TEXT,
        survey_datetime TIMESTAMP,
        doc_type TEXT
    )

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ CLASSIFICATION RULE (ëª¨ë“œ ìë™ ë¶„ê¸°)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Given a user query, classify whether it is:

A) structured panel filtering
   â†’ ì„±ë³„, ì—°ë ¹ëŒ€, ì§€ì—­, ì‘ë‹µ ì‹œì  ë“± ëª…í™•í•œ ì¡°ê±´ ê¸°ë°˜ ê²€ìƒ‰
   â†’ ì˜ˆ:  "20ëŒ€ ì—¬ì", "ì„œìš¸ ì‚¬ëŠ” ë‚¨ì", "30ëŒ€ ë‚¨ì„± ì‘ë‹µì"

B) semantic embedding search
   â†’ ì˜ë¯¸ ê¸°ë°˜ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ê²€ìƒ‰
   â†’ ì˜ˆ:  "ìš´ë™ ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒ", "ê°ì •ì ìœ¼ë¡œ ë¶ˆì•ˆí•œ 20ëŒ€", 
           "ì·¨í–¥ì´ ë¹„ìŠ·í•œ ì‘ë‹µì", "ìŠ¤íŠ¸ë ˆìŠ¤ ë§ì€ ì¸µ"

C) hybrid search (structured + semantic)
   â†’ ì˜ë¯¸ ê¸°ë°˜ + êµ¬ì¡°ì  í•„í„° ê²°í•©
   â†’ ì˜ˆ: "ìš´ë™ ì¢‹ì•„í•˜ëŠ” 30ëŒ€ ë‚¨ì"

You must classify the user query into one of:
  "structured", "semantic", "hybrid"

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ OUTPUT FORMAT
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ALWAYS RETURN JSON ONLY.

(1) Structured Query (íŒ¨ë„ ê²€ìƒ‰ ëª¨ë“œ):

{
  "type": "structured",
  "filters": { ... }, 
  "sql": "SELECT ... FROM core.doc_embedding_view ... WHERE ..."
}

(2) Semantic Query (ì˜ë¯¸ ê²€ìƒ‰ ëª¨ë“œ):

{
  "type": "semantic",
  "search_text": "TEXT_TO_EMBED",
  "sql": "SELECT ... JOIN ... ORDER BY distance LIMIT 10"
}

(3) Hybrid Query (êµ¬ì¡°ì  + ì˜ë¯¸ ê²€ìƒ‰):

{
  "type": "hybrid",
  "search_text": "TEXT_TO_EMBED",
  "filters": { ... },
  "sql": "SELECT ... JOIN ... WHERE ... ORDER BY distance LIMIT 10"
}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ SEMANTIC SEARCH SQL TEMPLATE (í•„ìˆ˜)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SELECT 
    v.doc_id,
    v.embedding_text AS content,
    v.gender,
    v.age_text,
    v.region,
    e.embedding <=> '<VECTOR>'::vector AS distance
FROM core.doc_embedding_view v
JOIN core.doc_embedding e ON v.doc_id = e.doc_id
{WHERE_CLAUSE_IF_NEEDED}
ORDER BY distance
LIMIT 10;

CRITICAL RULES (MUST FOLLOW):
1. ALWAYS use JOIN with v and e.
2. ALWAYS return ORDER BY distance LIMIT 10 (NO EXCEPTIONS!).
3. NEVER include <VECTOR> replacement. Backend will replace it.
4. LIMIT 10 is MANDATORY - NEVER omit it, NEVER use different values.
5. For hybrid queries, add WHERE filters BEFORE ORDER BY:
   - Example: WHERE v.gender = 'M' AND v.age_text LIKE '30%'
   - WHERE must come BEFORE ORDER BY, not after
6. NEVER add threshold filtering like:
   - "WHERE distance < 0.5"
   - "WHERE 1 - (embedding <=> ...) > 0.3"
   - "AND distance < X"
7. For semantic-only queries, use NO WHERE clause.
8. For hybrid queries, WHERE must contain ONLY structured filters (gender, age, region).

OUTPUT VALIDATION:
- Every semantic SQL MUST end with: "ORDER BY distance LIMIT 10"
- If LIMIT is missing, the query will FAIL.
- If threshold is added, the query will FAIL.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ FILTER EXTRACTION RULE (Structured/Hybrid)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
If the question includes:
- ì„±ë³„(ë‚¨ì/ì—¬ì/ë‚¨ì„±/ì—¬ì„±) â†’ gender
- ì—°ë ¹ëŒ€(10ëŒ€,20ëŒ€,30ëŒ€â€¦) â†’ age_range
- ì§€ì—­(ì„œìš¸/ê²½ê¸°/ë¶€ì‚°/ëŒ€êµ¬â€¦) â†’ region

Extract them into filters JSON:

"filters": {
   "gender": "M" or "F",
   "age": "20s" or "30s" etc,
   "region": "ì„œìš¸"
}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Œ BEHAVIOR SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. ì´í•´ â†’ Query classification
2. structuredë©´ SQL WHERE ì¤‘ì‹¬ìœ¼ë¡œ ìƒì„±
3. semanticì´ë©´ search_text + semantic SQL ìƒì„± (LIMIT 10 í•„ìˆ˜!)
4. hybridë©´ filters + search_text + semantic SQL ìƒì„± (WHERE + LIMIT 10 í•„ìˆ˜!)
5. ALWAYS output JSON only.

CRITICAL REMINDERS:
- Semantic SQL MUST ALWAYS end with "ORDER BY distance LIMIT 10"
- NEVER add threshold filtering (distance < X, similarity > Y)
- Hybrid queries: WHERE filters BEFORE ORDER BY
- If LIMIT 10 is missing, the backend will FAIL

If a query makes no sense:
{
  "type": "error",
  "message": "í•´ë‹¹ ì§ˆì˜ë¥¼ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
}
"""
        
        try:
            response = self.client.messages.create(
                model=model,
                max_tokens=1024,
                temperature=0,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": user_question}
                ],
            )
            
            # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = "\n".join(getattr(c, "text", "") for c in response.content if getattr(c, "type", None) == "text")
            
            # JSON íŒŒì‹± ì‹œë„
            import json
            import re
            try:
                # JSON ì½”ë“œ ë¸”ë¡ ì œê±° ì‹œë„
                if "```json" in text:
                    text = text.split("```json")[1].split("```")[0].strip()
                elif "```" in text:
                    text = text.split("```")[1].split("```")[0].strip()
                
                # JSON ê°ì²´ë§Œ ì¶”ì¶œ (ì²« ë²ˆì§¸ { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€)
                # LLMì´ JSON ë’¤ì— ì¶”ê°€ ì„¤ëª…ì„ ë¶™ì´ëŠ” ê²½ìš° ëŒ€ë¹„
                json_match = re.search(r'\{.*\}', text, re.DOTALL)
                if json_match:
                    text = json_match.group(0)
                
                result = json.loads(text)
                
                # type í•„ë“œ í™•ì¸
                query_type = result.get("type", "").lower()
                
                if query_type == "error":
                    return {
                        "error": result.get("reason", "Unknown error"),
                        "raw_response": text
                    }
                
                # structured ì¿¼ë¦¬ì¸ ê²½ìš°
                if query_type == "structured":
                    if "sql" not in result:
                        return {
                            "error": "LLM ì‘ë‹µì— sqlì´ ì—†ìŠµë‹ˆë‹¤.",
                            "raw_response": text
                        }
                    return {
                        "type": "structured",
                        "filters": result.get("filters", {}),
                        "sql": result["sql"]
                    }
                
                # semantic ì¿¼ë¦¬ì¸ ê²½ìš°
                if query_type == "semantic":
                    if "search_text" not in result or "sql" not in result:
                        return {
                            "error": "LLM ì‘ë‹µì— search_text ë˜ëŠ” sqlì´ ì—†ìŠµë‹ˆë‹¤.",
                            "raw_response": text
                        }
                    
                    # SQLì— <VECTOR> í”Œë ˆì´ìŠ¤í™€ë”ê°€ ìˆëŠ”ì§€ í™•ì¸
                    if "<VECTOR>" not in result.get("sql", ""):
                        return {
                            "error": "SQL ì¿¼ë¦¬ì— <VECTOR> í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì—†ìŠµë‹ˆë‹¤.",
                            "raw_response": text
                        }
                    
                    return {
                        "type": "semantic",
                        "search_text": result["search_text"],
                        "sql": result["sql"]
                    }
                
                # hybrid ì¿¼ë¦¬ì¸ ê²½ìš°
                if query_type == "hybrid":
                    if "search_text" not in result or "sql" not in result:
                        return {
                            "error": "LLM ì‘ë‹µì— search_text ë˜ëŠ” sqlì´ ì—†ìŠµë‹ˆë‹¤.",
                            "raw_response": text
                        }
                    
                    # SQLì— <VECTOR> í”Œë ˆì´ìŠ¤í™€ë”ê°€ ìˆëŠ”ì§€ í™•ì¸
                    if "<VECTOR>" not in result.get("sql", ""):
                        return {
                            "error": "SQL ì¿¼ë¦¬ì— <VECTOR> í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì—†ìŠµë‹ˆë‹¤.",
                            "raw_response": text
                        }
                    
                    return {
                        "type": "hybrid",
                        "search_text": result["search_text"],
                        "filters": result.get("filters", {}),
                        "sql": result["sql"]
                    }
                
                # typeì´ ì—†ìœ¼ë©´ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜ì„±)
                if "search_text" in result and "sql" in result:
                    if "<VECTOR>" not in result.get("sql", ""):
                        return {
                            "error": "SQL ì¿¼ë¦¬ì— <VECTOR> í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì—†ìŠµë‹ˆë‹¤.",
                            "raw_response": text
                        }
                    return {
                        "type": "semantic",
                        "search_text": result["search_text"],
                        "sql": result["sql"]
                    }
                
                return {
                    "error": "LLM ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. type í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                    "raw_response": text
                }
            except json.JSONDecodeError:
                return {
                    "error": "LLM ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "raw_response": text
                }
        except Exception as e:
            return {
                "error": f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
            }


